CNN神经网络架构至少包含一个卷积层 (tf.nn.conv2d)。单层CNN检测边缘。图像识别分类，使用不同层类型支持卷积层，减少过拟合，加速训练过程，降低内存占用率。

TensorFlow加速所有不同类弄卷积层卷积运算。tf.nn.depthwise_conv2d，一个卷积层输出边接到另一个卷积层输入，创建遵循Inception架构网络 Rethinking the Inception Architecture for Computer Vision 
https://arxiv.org/abs/1512.00567 。tf.nn.separable_conv2d，规模较大模型不牺牲准确率加速训练，规模小模型快速收敛但准确率低。tf.nn.conv2d_transpos，卷积核用于新特征图，每部分填充卷积核相同值，卷积核遍历新图像，重叠部分相加。斯坦福大学课程CS231n Winter 2016:Lecture 13。

激活函数与其他层输出生成特征图，对某些运算结果平滑(微分)，为神经网络引入非线性(输入输出曲线关系)，刻画输入复杂变化，训练复杂模型。激活函数主要因素，单调，输出随输入增长，可用梯度下降法找局部极值点；可微分，定义域内任意一点有导数，输出可用梯度下降法。
tf.nn.relu，修正线性单元，斜坡函数。分段线性，输入非负输出相同，输入为负输出为0。不受“梯度消失”影响，取值范围[0, +∞]。较大学习速率时，易受饱和神经元影响。损失信息但性能突出。输入秩1张量(向量)，小于0置0，其余分量不变。
 tf.sigmoid，只接收浮点数，返回区间[0.0, 1.0]内的值。输入值较大返回接近1.0，输入值较小返回接近0.0。适用于真实输出位于[0.0, 1.0]。输入接近饱和或变化剧烈，输出范围缩减成为问题。输入0，输出0.5，sigmoid函数值域中间点。
tf.tanh，双曲正切函数，值域[-1.0, 1.0]，有输出负值能力。值域中间点为0.0。网络下层期待输入为负值或0.0，会有问题。
tf.nn.dropout，依据可配置概率输出设0.0。适合少量随机性有助于训练。keep_prob参数指定输出保持概率。每次执行，不同输出。丢弃输出设为0.0。

池化层减少过拟合，减小输入尺寸，提高性能。输入降采样，为后续层保留重要信息。池化层减小尺寸效率比tf.nn.conv2d高。
tf.nn.max_pool，跳跃遍历张量，卷积核覆盖元素最大数值作卷积结果。适合输入数据灰度与图像重要性相关。输入为前一层输出，非直接图像。跨度strides使用image_height、image_width遍历输入。只保留输入张量最大元素。最大池化(max-pooling)，利用接受域(卷积核)完成。2X2接受域，单个通路最小数量降采样。1X1接受域，输出输入相同。
tf.nn.avg_pool，跳跃遍历张量，卷积核覆盖各深度值取平均。适合卷积核重要，实现值缩减。如输入张量宽度高度大，深度小。

tf.nn.relu是无界函数，归一化识别高频特征。tf.nn.local_response_normalization(tf.nn.lrn)，局部响应归一化，给定向量，每个分量被depth_radius覆盖输入加权和除。输入保持在可接受范围。考虑每个值重要性。归一化输出调整到区间[-1.0, 1.0]。

高级层减少代码冗余，遵循最佳实践。
tf.contrib.layers.convolution2d。权值初始化、偏置初始化、可训练变量输出、偏置相加、添加激活函数。卷积核，可训练变量。权值初始化用于卷积核首次运行值填充(tf.truncated_normal)。简单元组形式表示卷积核高度和宽度。输入图像，tf.image.convert_image_dtype，调整各分量表示颜色值。TensorFlow要求浮点型描述图像颜色，分量在[0, 1]。
tf.contrib.layers.fully_connected。全连接层，每个输入输出存在连接。CNN最后一层常是全连接层。TensorFlow全连接层格式，tf.matmul(features,weight)+bias。输入张量与输出层每个神经元连接。

原始输入需要传递给输入层。目标识别与分类输入层tf.nn.conv2d。


    import tensorflow as tf
    features = tf.range(-2, 3)
    print features
    sess = tf.Session()
    print sess.run([features, tf.nn.relu(features)])
    features2 = tf.to_float(tf.range(-1, 3))
    print features2
    print sess.run([features2, tf.sigmoid(features2)])
    print sess.run([features2, tf.tanh(features2)])
    features3 = tf.constant([-0.1, 0.0, 0.1, 0.2])
    print features3
    print sess.run([features3, tf.nn.dropout(features3, keep_prob=0.5)])
    batch_size = 1
    input_height = 3
    input_width = 3
    input_channels = 1
    layer_input = tf.constant([
            [
                [[1.0], [0.2], [1.5]],
                [[0.1], [1.2], [1.4]],
                [[1.1], [0.4], [0.4]]
            ]
        ])
    print layer_input
    kernel = [batch_size, input_height, input_width, input_channels]
    print kernel
    max_pool = tf.nn.max_pool(layer_input, kernel, [1, 1, 1, 1], "VALID")
    print max_pool
    print sess.run(max_pool)
    layer_input2 = tf.constant([
            [
                [[1.0], [1.0], [1.0]],
                [[1.0], [0.5], [0.0]],
                [[0.0], [0.0], [0.0]]
            ]
        ])
    print layer_input2
    avg_pool = tf.nn.avg_pool(layer_input2, kernel, [1, 1, 1, 1], "VALID")
    print avg_pool
    print sess.run(avg_pool)
    layer_input3 = tf.constant([
            [
                [[1.], [2.], [3.]]
            ]
        ])
    print layer_input3
    lrn = tf.nn.local_response_normalization(layer_input3)
    print lrn
    print sess.run([layer_input3, lrn])
    image_input = tf.constant([
            [
                [[0., 0., 0.], [255., 255., 255.], [254., 0., 0.]],
                [[0., 191., 0.], [3., 108., 233.], [0., 191., 0.]],
                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.]]
            ]
        ])
    print image_input
    conv2d = tf.contrib.layers.convolution2d(
        image_input,
        num_outputs=4,
        kernel_size=(1,1),
        activation_fn=tf.nn.relu,
        stride=(1,1),
        trainable=True)
    print conv2d
    sess.run(tf.global_variables_initializer())
    print sess.run(conv2d)
    features4 = tf.constant([
            [[1.2], [3.4]]
        ])
    print features4
    fc = tf.contrib.layers.fully_connected(features4, num_outputs=2)
    print fc
    sess.run(tf.global_variables_initializer())
    print sess.run(fc)


参考资料：
《面向机器智能的TensorFlow实践》


